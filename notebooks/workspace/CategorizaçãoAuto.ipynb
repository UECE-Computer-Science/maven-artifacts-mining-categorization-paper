{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473632f-fc81-40a1-910b-8204e16e754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo gerado com sucesso: categorized_artifacts.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_csv = 'TAGS_noCategorizeds.csv'  \n",
    "categories_txt = 'Categorias para TAGs.txt'  \n",
    "output_csv = 'categorized_artifacts.csv' \n",
    "\n",
    "\n",
    "def load_categories(txt_file):\n",
    "    with open(txt_file, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    category_mapping = {}\n",
    "    current_category = None\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.endswith(':'):\n",
    "            current_category = line[:-1]  \n",
    "        elif line.startswith('#') and current_category:\n",
    "            tag = line.strip()\n",
    "            category_mapping[tag] = current_category  \n",
    "    \n",
    "    return category_mapping\n",
    "\n",
    "category_mapping = load_categories(categories_txt)\n",
    "\n",
    "data = pd.read_csv(input_csv)\n",
    "\n",
    "def map_tags_to_categories(tags):\n",
    "    categories = []\n",
    "    for tag in tags:\n",
    "        if tag in category_mapping:\n",
    "            categories.append(category_mapping[tag])\n",
    "    return categories\n",
    "\n",
    "data['CategoryList'] = data['TAG'].apply(lambda x: map_tags_to_categories(eval(x)))\n",
    "\n",
    "data = data.explode('CategoryList')\n",
    "\n",
    "data = data.rename(columns={'CategoryList': 'Category'})\n",
    "\n",
    "grouped = data.groupby('ArtifactID')\n",
    "\n",
    "results = []\n",
    "\n",
    "for artifact, group in grouped:\n",
    "    if not group['Category'].empty:\n",
    "        mode_value = group['Category'].mode()\n",
    "        if not mode_value.empty:\n",
    "            results.append({'ArtifactID': artifact, 'Category': mode_value[0]})\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "result_df.to_csv(output_csv, index=False)\n",
    "print(f\"File generated successfully: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679ef11-cc4d-4033-9b12-e63df8a81e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def contar_artifacts_por_categoria(input_file, output_file):\n",
    "    categorias = []\n",
    "    \n",
    "    with open(input_file, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  \n",
    "        for row in reader:\n",
    "            if row:  \n",
    "                categoria = row[1]  \n",
    "                categorias.append(categoria)\n",
    "    \n",
    "    categoria_contagem = Counter(categorias)\n",
    "    \n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['category', 'amount'])\n",
    "        for categoria, numero in categoria_contagem.most_common():\n",
    "            writer.writerow([categoria, numero])\n",
    "\n",
    "\n",
    "input_file = 'categorized_artifacts_oficial_V1.csv'\n",
    "output_file = 'category_count.csv'\n",
    "\n",
    "contar_artifacts_por_categoria(input_file, output_file)\n",
    "\n",
    "print(f\"File generated successfully: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ec5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "# Function to calculate percentage and perform stratified sampling\n",
    "def analyze_and_sample(input_file, output_file, sample_size):\n",
    "    categories = []\n",
    "    category_count = {}\n",
    "    total_count = 0\n",
    "\n",
    "    # Read the input CSV and calculate total and category counts\n",
    "    with open(input_file, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            category = row[1]\n",
    "            count = int(row[2])  # The number of artifacts for that category\n",
    "            total_count += count\n",
    "            category_count[category] = count\n",
    "            categories.append((category, count))\n",
    "\n",
    "    # Calculate the percentage for each category\n",
    "    category_percentages = {category: (count / total_count) * 100 for category, count in category_count.items()}\n",
    "\n",
    "    # Stratified sampling\n",
    "    stratified_sample = []\n",
    "    for category, count in categories:\n",
    "        sample_size_category = round((count / total_count) * sample_size)  # Proportional sample size\n",
    "        stratified_sample.extend([category] * sample_size_category)  # Add category to sample\n",
    "\n",
    "    # Randomly sample from the stratified list\n",
    "    random.shuffle(stratified_sample)  # Shuffle to randomize the selection\n",
    "    sample = stratified_sample[:sample_size]\n",
    "\n",
    "    # Write the results (percentage and stratified sample) to a new CSV\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['category', 'numero', 'percentage', 'sampled'])  # Header\n",
    "        for category in category_count:\n",
    "            writer.writerow([category, category_count[category], category_percentages[category], category in sample])\n",
    "\n",
    "    print(f\"Analysis complete. Results saved to {output_file}\")\n",
    "\n",
    "# Input file with category and number of artifacts\n",
    "input_file = 'category_count.csv'  # Replace with your CSV file path\n",
    "output_file = 'analyzed_and_sampled.csv'  # Output CSV file path\n",
    "sample_size = 378  # Sample size to select\n",
    "\n",
    "analyze_and_sample(input_file, output_file, sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d3cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "# Function to randomly select rows based on weighted probabilities\n",
    "def weighted_random_sample(input_file, output_file, sample_size):\n",
    "    categories = []\n",
    "    category_weights = []\n",
    "    \n",
    "    # Read the input CSV and prepare the categories and weights\n",
    "    with open(input_file, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            category = row[1]\n",
    "            count = int(row[2])  # The number of artifacts for that category\n",
    "            categories.append((category, count))\n",
    "            category_weights.append(count)\n",
    "\n",
    "    # Randomly select the specified number of rows based on weights\n",
    "    sampled_categories = random.choices(categories, weights=category_weights, k=sample_size)\n",
    "\n",
    "    # Write the selected samples to the output CSV\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['category', 'numero'])  # Header\n",
    "        for category, count in sampled_categories:\n",
    "            writer.writerow([category, count])\n",
    "\n",
    "    print(f\"Random sampling complete. Results saved to {output_file}\")\n",
    "\n",
    "# Input file with category and number of artifacts\n",
    "input_file = 'categoria_count.csv'  # Replace with your CSV file path\n",
    "output_file = 'random_sampled.csv'  # Output CSV file path\n",
    "sample_size = 378  # Sample size to select\n",
    "\n",
    "weighted_random_sample(input_file, output_file, sample_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
